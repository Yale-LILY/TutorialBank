project_id, title, abstract
"1","Adversarial Connective-exploiting Networks for Implicit Discourse Relation Classification","Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues, which motivates the use of annotated implicit connectives to improve the recognition. We propose a feature imitation frame-work in which an implicit relation network is driven to learn from another neural network with access to connectives, and thus encouraged to extract similarly salient features for accurate classification. We develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator. Our method effectively transfers discriminability of connectives to the implicit features, and achieves state-of-the-art performance on the PDTB benchmark.",
"2","Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access"," This  paper  proposes KB-InfoBot —  a multi-turn   dialogue   agent   which   helps users   search   Knowledge   Bases   (KBs) without  composing  complicated  queries. Such  goal-oriented  dialogue  agents  typically  need  to  interact  with  an  external database to access real-world knowledge. Previous systems achieved this by issuing a symbolic query to the KB to retrieve entries  based  on  their  attributes.   However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents. In  this  paper,  we  address  this  limitation by replacing symbolic queries with an induced “soft” posterior distribution over the KB that indicates which entities the user is interested in. Integrating the soft retrieval process with a reinforcement learner leads to higher task success rate and reward in both simulations  and  against  real  users. We also present a fully neural end-to-end agent, trained entirely from user feedback, and discuss its application towards personalized dialogue agents.",
"3"," Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders","While    recent    neural    encoder-decoder models have shown great promise in modeling   open-domain   conversations,   they often generate dull and generic responses. Unlike  past  work  that  has  focused  on diversifying  the  output  of  the  decoder at  word-level  to  alleviate  this  problem, we  present  a  novel  framework  based  on conditional  variational  autoencoders  that captures  the  discourse-level  diversity  in the encoder.  Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse  responses  using  only  greedy  decoders. We have further developed a novel variant  that  is  integrated  with  linguistic prior  knowledge  for  better  performance. Finally, the training procedure is improved by  introducing  a bag-of-word loss.   Our proposed   models   have   been   validated to   generate   significantly   more   diverse responses  than  baseline  approaches  and exhibit   competence   in   discourse-level decision-making.",
"4","Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network"," Cognitive NLP systems - i.e. , NLP systems that make use of behavioral data - augment traditional text-based features with cognitive features extracted from eye-movement patterns, EEG signals, brain-imaging etc.. Such  extraction  of  features  is  typically manual.  We contend that manual extraction of features may not be the best way to tackle text subtleties that characteristically prevail in complex classification tasks like sentiment analysis and sarcasm detection , and that even the extraction and choice of features should be delegated to the learning  system.  We  introduce  a  framework to automatically extract cognitive features from the eye-movement / gaze data of human readers reading the text and use them as features along with textual features for the  tasks  of  sentiment  polarity  and  sarcasm detection.  Our proposed framework is based on Convolutional Neural Network (CNN).  The  CNN learns features  from both gaze and text and uses them to classify the input text.  We test our technique on  published  sentiment  and  sarcasm  labeled  datasets,  enriched  with  gaze  information, to show that using a combination of automatically learned text and gaze features often yields better classification performance over (i) CNN based systems that rely  on  text  input  alone  and  (ii)  existing systems that rely on handcrafted gaze and textual features.                ",
"5","TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension","We    present    TriviaQA,    a    challenging reading  comprehension  dataset  containing  over  650K  question-answer-evidence triples.  TriviaQA includes 95K question-answer  pairs  authored  by  trivia  enthusiasts and independently gathered evidence documents,  six  per  question  on  average, that  provide  high  quality  distant  supervision  for  answering  the  questions.   We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions,  (2)  has  considerable  syntactic and  lexical  variability  between  questions and  corresponding  answer-evidence  sentences,  and  (3)  requires  more  cross  sentence reasoning to find answers.  We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging test bed that is worth significant future study.",
"6","A Teacher-Student Framework for Zero-Resource Neural Machine Translation","While end-to-end neural machine translation (NMT) has made remarkable progress recently,   it   still   suffers   from   the   data scarcity   problem   for   low-resource   language  pairs  and  domains.   In  this  paper, we  propose  a  method  for  zero-resource NMT by assuming that parallel sentences share  close  probabilities  of  generating  a sentence  in  a  third  language.   Based  on this  assumption,  our  method  is  able  to train a source-to-target NMT model (“student”) without parallel corpora available, guided by an existing pivot-to-target NMT model  (“teacher”)  on  a  source-pivot  parallel  corpus.   Experimental  results  show that the proposed method significantly improves over a baseline pivot-based model by +3.0 BLEU points across various language pairs.",
"7","Obtaining referential word meanings from visual and distributional information: Experiments on object naming","We investigate object naming, which is an important sub-task of referring expression generation on real-world images. As opposed to mutually exclusive labels used in object recognition, object names are more flexible, subject to communicative preferences and semantically related to each other. Therefore, we investigate models of referential word meaning that link visual to lexical information which we assume to be given through distributional word embeddings. We present a model that learns individual predictors for object names that link visual and distributional aspects of word meaning during training. We show that this is particularly beneficial for zero-shot learning, as compared to projecting visual objects directly into the distributional space. In a standard object naming task, we find that different ways of combining lexical and visual information achieve very similar performance, though experiments on model combination suggest that they capture complementary aspects of referential meaning.",
"8","EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks","Accurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding  individuals  and  their  lives. However,  progress  on  emotion  detection has been hampered by the absence of large labeled  datasets.   In  this  work,  we  build a very large dataset for fine-grained emotions  and  develop  deep  learning  models on  it.   We  achieve  a  new  state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58%).  We also extend  the  task  beyond  emotion  types  to model  Robert  Plutchik’s  8  primary  emotion dimensions,  acquiring a superior accuracy of 95.68%.",
"9","Neural End-to-End Learning for Computational Argumentation Mining","We investigate neural techniques for end-to-end computational argumentation mining (AM). We frame AM both as a token-based dependency parsing and as a token-based sequence tagging problem, including a multi-task learning setup. Contrary to models that operate on the argument component level, we find that framing AM as dependency parsing leads to subpar performance results.  In contrast, less complex (local) tagging models based on Bi-LSTMs perform robustly across classification scenarios, being able to catch long-range dependencies inherent to the AM problem.  Moreover, we find that jointly learning ‘natural’ subtasks, in a multi-task learning setup, improves performance.",
"10","Unifying Text, Metadata, and User Network Representations with a Neural Network for Geolocation Prediction","We propose a novel geolocation prediction model using a complex neural network. Our model unifies text, metadata, and user network representations with an attention mechanism to overcome previous ensemble approaches. In an evaluation using two open datasets, the proposed model exhibited a maximum 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy against previous models. We further analyzed several intermediate layers of our model, which revealed that their states capture some statistical characteristics of the datasets",
